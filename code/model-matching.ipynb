{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "\n",
    "path='../reports/corpus.xlsx'\n",
    "descriptions = [preprocess_text(element) for element in get_column_values(path, 'descriptions_measures', 'A')]\n",
    "targets = [preprocess_text(element) for element in get_column_values(path, 'descriptions_measures', 'B')]\n",
    "models = ['bow','tfidf','word2vec','sbert']\n",
    "preprocessing = True\n",
    "version_w2v = 'word2vec-google-news-300'\n",
    "version_sbert = 'bert-base-nli-mean-tokens'\n",
    "version_bow = 'preprocessedbow_model.joblib'\n",
    "version_tfidf = 'preprocessedtfidf_model.joblib'\n",
    "corpus = ['Descriptions']\n",
    "tm = TextModels(excel_path=path, columns=corpus,\n",
    "                 word2vec_version=version_w2v, sbert_model=version_sbert)\n",
    "n = 7\n",
    "\n",
    "for model in models:\n",
    "    if model == 'bow':\n",
    "        version = version_bow\n",
    "        candidate_templates(descriptions=descriptions, targets=targets, \n",
    "                    model=model, version=version, tm=tm, preprocessing=preprocessing, path=path, n=n)\n",
    "    elif model == 'tfidf':\n",
    "        version = version_tfidf\n",
    "        candidate_templates(descriptions=descriptions, targets=targets, \n",
    "            model=model, version=version, tm=tm, preprocessing=preprocessing, path=path, n=n)\n",
    "    elif model == 'word2vec':\n",
    "        version = version_w2v\n",
    "        candidate_templates(descriptions=descriptions, targets=targets, \n",
    "            model=model, version=version, tm=tm, preprocessing=preprocessing, path=path, n=n)\n",
    "    elif model == 'sbert':\n",
    "        version = version_sbert\n",
    "        candidate_templates(descriptions=descriptions, targets=targets, \n",
    "            model=model, version=version, tm=tm, preprocessing=preprocessing, path=path, n=n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m version_tfidf \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtfidf_model.joblib\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     12\u001b[0m corpus \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mDescriptions\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 13\u001b[0m tm \u001b[39m=\u001b[39m TextModels(excel_path\u001b[39m=\u001b[39;49mpath, columns\u001b[39m=\u001b[39;49mcorpus,\n\u001b[0;32m     14\u001b[0m                  word2vec_version\u001b[39m=\u001b[39;49mversion_w2v, sbert_model\u001b[39m=\u001b[39;49mversion_sbert)\n\u001b[0;32m     15\u001b[0m n \u001b[39m=\u001b[39m \u001b[39m7\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n",
      "File \u001b[1;32mc:\\Users\\avitsas\\Documents\\thesis\\code\\textmodels.py:35\u001b[0m, in \u001b[0;36mTextModels.__init__\u001b[1;34m(self, excel_path, columns, word2vec_version, w2v_window, w2v_workers, sbert_model, cbow_window)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbow_vectorizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtfidf_vectorizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword2vec_model \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39;49mload(word2vec_version)\n\u001b[0;32m     36\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39men_core_web_sm\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw2v_window \u001b[39m=\u001b[39m w2v_window\n",
      "File \u001b[1;32mc:\\Users\\avitsas\\Anaconda3\\envs\\project\\lib\\site-packages\\gensim\\downloader.py:503\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, return_path)\u001b[0m\n\u001b[0;32m    501\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, BASE_DIR)\n\u001b[0;32m    502\u001b[0m module \u001b[39m=\u001b[39m \u001b[39m__import__\u001b[39m(name)\n\u001b[1;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39;49mload_data()\n",
      "File \u001b[1;32m~/gensim-data\\glove-twitter-200\\__init__.py:8\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_data\u001b[39m():\n\u001b[0;32m      7\u001b[0m \tpath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(base_dir, \u001b[39m'\u001b[39m\u001b[39mglove-twitter-200\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglove-twitter-200.gz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \tmodel \u001b[39m=\u001b[39m KeyedVectors\u001b[39m.\u001b[39;49mload_word2vec_format(path)\n\u001b[0;32m      9\u001b[0m \t\u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\avitsas\\Anaconda3\\envs\\project\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1719\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1672\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m   1673\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_word2vec_format\u001b[39m(\n\u001b[0;32m   1674\u001b[0m         \u001b[39mcls\u001b[39m, fname, fvocab\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m, unicode_errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1675\u001b[0m         limit\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, datatype\u001b[39m=\u001b[39mREAL, no_header\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1676\u001b[0m     ):\n\u001b[0;32m   1677\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m \n\u001b[0;32m   1679\u001b[0m \u001b[39m    Warnings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1717\u001b[0m \n\u001b[0;32m   1718\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1719\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_word2vec_format(\n\u001b[0;32m   1720\u001b[0m         \u001b[39mcls\u001b[39;49m, fname, fvocab\u001b[39m=\u001b[39;49mfvocab, binary\u001b[39m=\u001b[39;49mbinary, encoding\u001b[39m=\u001b[39;49mencoding, unicode_errors\u001b[39m=\u001b[39;49municode_errors,\n\u001b[0;32m   1721\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit, datatype\u001b[39m=\u001b[39;49mdatatype, no_header\u001b[39m=\u001b[39;49mno_header,\n\u001b[0;32m   1722\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\avitsas\\Anaconda3\\envs\\project\\lib\\site-packages\\gensim\\models\\keyedvectors.py:2069\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   2065\u001b[0m         _word2vec_read_binary(\n\u001b[0;32m   2066\u001b[0m             fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding\n\u001b[0;32m   2067\u001b[0m         )\n\u001b[0;32m   2068\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2069\u001b[0m         _word2vec_read_text(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\n\u001b[0;32m   2070\u001b[0m \u001b[39mif\u001b[39;00m kv\u001b[39m.\u001b[39mvectors\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(kv):\n\u001b[0;32m   2071\u001b[0m     logger\u001b[39m.\u001b[39minfo(\n\u001b[0;32m   2072\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mduplicate words detected, shrinking matrix size from \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2073\u001b[0m         kv\u001b[39m.\u001b[39mvectors\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39mlen\u001b[39m(kv),\n\u001b[0;32m   2074\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\avitsas\\Anaconda3\\envs\\project\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1971\u001b[0m, in \u001b[0;36m_word2vec_read_text\u001b[1;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[0;32m   1969\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_word2vec_read_text\u001b[39m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding):\n\u001b[0;32m   1970\u001b[0m     \u001b[39mfor\u001b[39;00m line_no \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(vocab_size):\n\u001b[1;32m-> 1971\u001b[0m         line \u001b[39m=\u001b[39m fin\u001b[39m.\u001b[39;49mreadline()\n\u001b[0;32m   1972\u001b[0m         \u001b[39mif\u001b[39;00m line \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1973\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munexpected end of input; is count incorrect or file otherwise damaged?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\avitsas\\Anaconda3\\envs\\project\\lib\\gzip.py:398\u001b[0m, in \u001b[0;36mGzipFile.readline\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadline\u001b[39m(\u001b[39mself\u001b[39m, size\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m    397\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_not_closed()\n\u001b[1;32m--> 398\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer\u001b[39m.\u001b[39;49mreadline(size)\n",
      "File \u001b[1;32mc:\\Users\\avitsas\\Anaconda3\\envs\\project\\lib\\_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadinto\u001b[39m(\u001b[39mself\u001b[39m, b):\n\u001b[0;32m     67\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b) \u001b[39mas\u001b[39;00m view, view\u001b[39m.\u001b[39mcast(\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m byte_view:\n\u001b[1;32m---> 68\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m(byte_view))\n\u001b[0;32m     69\u001b[0m         byte_view[:\u001b[39mlen\u001b[39m(data)] \u001b[39m=\u001b[39m data\n\u001b[0;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(data)\n",
      "File \u001b[1;32mc:\\Users\\avitsas\\Anaconda3\\envs\\project\\lib\\gzip.py:495\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39m# Read a chunk of data from the file\u001b[39;00m\n\u001b[0;32m    493\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread(io\u001b[39m.\u001b[39mDEFAULT_BUFFER_SIZE)\n\u001b[1;32m--> 495\u001b[0m uncompress \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decompressor\u001b[39m.\u001b[39;49mdecompress(buf, size)\n\u001b[0;32m    496\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39munconsumed_tail \u001b[39m!=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    497\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mprepend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39munconsumed_tail)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from helper import *\n",
    "\n",
    "path='../reports/corpus.xlsx'\n",
    "descriptions = get_column_values(path, 'descriptions_measures', 'A')\n",
    "targets = get_column_values(path, 'descriptions_measures', 'B')\n",
    "models = ['bow','tfidf','word2vec','sbert']\n",
    "preprocessing = False\n",
    "version_w2v = 'glove-twitter-200'\n",
    "version_sbert = 'bert-base-nli-mean-tokens'\n",
    "version_bow = 'bow_model.joblib'\n",
    "version_tfidf = 'tfidf_model.joblib'\n",
    "corpus = ['Descriptions']\n",
    "tm = TextModels(excel_path=path, columns=corpus,\n",
    "                 word2vec_version=version_w2v, sbert_model=version_sbert)\n",
    "n = 7\n",
    "\n",
    "for model in models:\n",
    "    if model == 'bow':\n",
    "        version = version_bow\n",
    "        candidate_templates(descriptions=descriptions, targets=targets, \n",
    "                    model=model, version=version, tm=tm, preprocessing=preprocessing, path=path, n=n)\n",
    "    elif model == 'tfidf':\n",
    "        version = version_tfidf\n",
    "        candidate_templates(descriptions=descriptions, targets=targets, \n",
    "            model=model, version=version, tm=tm, preprocessing=preprocessing, path=path, n=n)\n",
    "    elif model == 'word2vec':\n",
    "        version = version_w2v\n",
    "        candidate_templates(descriptions=descriptions, targets=targets, \n",
    "            model=model, version=version, tm=tm, preprocessing=preprocessing, path=path, n=n)\n",
    "    elif model == 'sbert':\n",
    "        version = version_sbert\n",
    "        candidate_templates(descriptions=descriptions, targets=targets, \n",
    "            model=model, version=version, tm=tm, preprocessing=preprocessing, path=path, n=n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6730b402c0f33b6bed7f8d0f7f3f069d5734816b753f081e1b7690f9108853e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
