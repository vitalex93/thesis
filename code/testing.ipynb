{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "\n",
    "path='../reports/corpus.xlsx'\n",
    "\n",
    "description = get_column_values(path, 'descriptions_measures', 'A')\n",
    "\n",
    "\n",
    "targets = get_column_values(path, 'descriptions_measures', 'B')\n",
    "\n",
    "similarities_df = similarities_df(docs=description,group=targets,encoding_method='tfidf')\n",
    "\n",
    "similarities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "\n",
    "Q1 = 'Create a report that shows the number of settlement applications approved during the month, their approved amount,\\\n",
    "      the written off balance, the average days to approval, their average and median duration and their entry principal and balance, \\\n",
    "        for September 2020 per DCA and application type. The report should be produced on Earth portfolio. '\n",
    "\n",
    "path = '../reports/corpus.xlsx'\n",
    "targets = get_column_values(path, 'descriptions_measures', 'B')\n",
    "encoding_method = 'word2vec'\n",
    "version = 'word2vec-google-news-300'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "similarities_dict = get_similarity_scores(text=Q1,documents=targets,encoding_method=encoding_method,version=version)\n",
    "\n",
    "top_10 = get_first_n_keys(similarities_dict, 10)\n",
    "\n",
    "\n",
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "\n",
    "Q1 = 'Create a report that shows the number of settlement applications approved during the month, their approved amount,\\\n",
    "      the written off balance, the average days to approval, their average and median duration and their entry principal and balance, \\\n",
    "        for September 2020 per DCA and application type. The report should be produced on Earth portfolio. '\n",
    "\n",
    "processed_text = preprocess_text(Q1)\n",
    "\n",
    "\n",
    "\n",
    "w2v = api.load(\"word2vec-google-news-300\")\n",
    "vocab = w2v.index_to_key\n",
    "words = Q1.split()\n",
    "\n",
    "\n",
    "count = sum(1 for word in processed_text if word in w2v)\n",
    "existing_words = [word for word in processed_text if word in w2v]\n",
    "difference = len(words) - count\n",
    "\n",
    "pr, orig = get_unique_items(words, processed_text)\n",
    "\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['settlement duration 6 month included',\n",
       " 'settlement duration 7 12 month included',\n",
       " 'settlement duration 13 36 month included',\n",
       " 'settlement duration 37 72 month included',\n",
       " 'settlement duration 73 108 month included',\n",
       " 'settlement duration 109 month']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper import *\n",
    "\n",
    "path='../reports/corpus.xlsx'\n",
    "\n",
    "Q1 = 'Create a report that shows the number of settlement applications approved during the month, their approved amount,\\\n",
    "      the written off balance, the average days to approval, their average and median duration and their entry principal and balance, \\\n",
    "        for September 2020 per DCA and application type. The report should be produced on Earth portfolio. '\n",
    "\n",
    "Q2 = 'Provide a report that displays the number of accounts not in running settlements for the Earth portfolio, \\\n",
    "  their expected monthly payments at the end of the examined month and their actual monthly payments per DCA, for September 2020.'\n",
    "\n",
    "ground_truth = {'R1':[preprocess_text(element) for element in get_column_values(path, 'R1', 'C')],\n",
    "                        'R2':[preprocess_text(element) for element in get_column_values(path, 'R2', 'C')],\n",
    "                        'R3':[preprocess_text(element) for element in get_column_values(path, 'R3', 'C')],\n",
    "                        'R4':[preprocess_text(element) for element in get_column_values(path, 'R4', 'C')],\n",
    "                        'R5':[preprocess_text(element) for element in get_column_values(path, 'R5', 'C')],\n",
    "                        'R6':[preprocess_text(element) for element in get_column_values(path, 'R6', 'C')],\n",
    "                        'R7':[preprocess_text(element) for element in get_column_values(path, 'R7', 'C')],\n",
    "                        'R8':[preprocess_text(element) for element in get_column_values(path, 'R8', 'C')],\n",
    "                        'R9':[preprocess_text(element) for element in get_column_values(path, 'R9', 'C')]}   \n",
    "\n",
    "processed_text = preprocess_text(Q2)\n",
    "\n",
    "ground_truth['R4']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\avitsas\\Anaconda3\\envs\\project\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-words model saved to preprocessed_nums_bow_model.joblib\n",
      "TF-IDF model saved to preprocessed_nums_tfidf_model.joblib\n"
     ]
    }
   ],
   "source": [
    "from helper import *\n",
    "\n",
    "path='../reports/corpus.xlsx'\n",
    "descriptions = get_column_values(path, 'descriptions_measures', 'A')\n",
    "targets = get_column_values(path, 'descriptions_measures', 'B')\n",
    "models = ['bow','tfidf','word2vec','sbert']\n",
    "version_w2v = 'word2vec-google-news-300'\n",
    "version_sbert = 'bert-base-nli-mean-tokens'\n",
    "version_bow = 'bow_model.joblib'\n",
    "version_tfidf = 'tfidf_model.joblib'\n",
    "corpus = ['Descriptions']\n",
    "tm = TextModels(excel_path=path, columns=corpus,\n",
    "                 word2vec_version=version_w2v, sbert_model=version_sbert)\n",
    "\n",
    "tm.build_bow_model(preprocessing=True)\n",
    "tm.build_tfidf_model(preprocessing=True)\n",
    "\n",
    "tm.save_models('preprocessed_nums_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['settlement duration 109 month',\n",
       " 'settlement duration 6 month included',\n",
       " 'settlement duration 7 12 month included',\n",
       " 'settlement duration 13 36 month included',\n",
       " 'settlement duration 37 72 month included',\n",
       " 'settlement duration 73 108 month included',\n",
       " 'month arrears 1 month ago',\n",
       " 'application status previous month',\n",
       " 'settlement duration',\n",
       " 'payment prediction stray payer active settlement']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper import *\n",
    "\n",
    "path='../reports/corpus.xlsx'\n",
    "descriptions = [preprocess_text(element) for element in get_column_values(path, 'descriptions_measures', 'A')]\n",
    "targets = [preprocess_text(element) for element in get_column_values(path, 'descriptions_measures', 'B')]\n",
    "models = ['bow','tfidf','word2vec','sbert']\n",
    "preprocessing = True\n",
    "version_w2v = 'word2vec-google-news-300'\n",
    "version_sbert = 'bert-base-nli-mean-tokens'\n",
    "version_bow = 'preprocessedbow_model.joblib'\n",
    "version_tfidf = 'preprocessedtfidf_model.joblib'\n",
    "corpus = ['Descriptions']\n",
    "tm = TextModels(excel_path=path, columns=corpus,\n",
    "                 word2vec_version=version_w2v, sbert_model=version_sbert)\n",
    "n = 10\n",
    "\n",
    "df = results_to_targets(descriptions=descriptions,targets=targets,model='bow',version=version_bow,\n",
    "                        tm=tm, preprocessing=preprocessing,n=n,path=path, i=5)\n",
    "\n",
    "\n",
    "dictsim = get_similarities_for_values(values=descriptions, docs=targets,encoding_method='bow',version=version_bow,\n",
    "                                      tm=tm, n=n)\n",
    "\n",
    "dictsim['R4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\avitsas\\Anaconda3\\envs\\project\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[nan].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 32\u001b[0m\n\u001b[0;32m     26\u001b[0m Q8 \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCreate a report that shows the number of settlement applications approved during the month, their approved amount,\u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39m      the written off balance, the average days to approval, their average and median duration and their entry principal and balance, \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39m        for September 2020 per DCA and application type. The report should be produced on Earth portfolio. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     29\u001b[0m target_sample \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mBalance on arrangement creation\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 32\u001b[0m scores \u001b[39m=\u001b[39m get_similarity_scores(text\u001b[39m=\u001b[39;49mQ8, documents\u001b[39m=\u001b[39;49mtargets, encoding_method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mword2vec\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     33\u001b[0m                                version\u001b[39m=\u001b[39;49mversion_w2v, tm\u001b[39m=\u001b[39;49mtm, preprocessing\u001b[39m=\u001b[39;49mpreprocessing )\n\u001b[0;32m     36\u001b[0m scores\n",
      "File \u001b[1;32mc:\\Users\\avitsas\\Documents\\thesis\\code\\helper.py:19\u001b[0m, in \u001b[0;36mget_similarity_scores\u001b[1;34m(text, documents, encoding_method, version, tm, preprocessing)\u001b[0m\n\u001b[0;32m     16\u001b[0m     doc_encoding \u001b[39m=\u001b[39m encode_func(doc, encoding_method, version)\n\u001b[0;32m     17\u001b[0m     \u001b[39m#doc_encoding = doc_encoding.reshape(1, -1)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[39m#print (doc_encoding)\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     similarity_score \u001b[39m=\u001b[39m cosine_similarity([query_encoding], [doc_encoding])[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m     20\u001b[0m     similarity_scores[doc] \u001b[39m=\u001b[39m similarity_score\n\u001b[0;32m     22\u001b[0m \u001b[39m# Sort similarity scores in descending order\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\avitsas\\Anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1393\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1359\u001b[0m \n\u001b[0;32m   1360\u001b[0m \u001b[39mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[39m    Returns the cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[39m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1393\u001b[0m X, Y \u001b[39m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[0;32m   1395\u001b[0m X_normalized \u001b[39m=\u001b[39m normalize(X, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1396\u001b[0m \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m Y:\n",
      "File \u001b[1;32mc:\\Users\\avitsas\\Anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:163\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    156\u001b[0m         X,\n\u001b[0;32m    157\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m         estimator\u001b[39m=\u001b[39mestimator,\n\u001b[0;32m    162\u001b[0m     )\n\u001b[1;32m--> 163\u001b[0m     Y \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    164\u001b[0m         Y,\n\u001b[0;32m    165\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    166\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    167\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    168\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    169\u001b[0m         estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    170\u001b[0m     )\n\u001b[0;32m    172\u001b[0m \u001b[39mif\u001b[39;00m precomputed:\n\u001b[0;32m    173\u001b[0m     \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\avitsas\\Anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:902\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    901\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 902\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    903\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    905\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    906\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    907\u001b[0m         )\n\u001b[0;32m    909\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    910\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    913\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[nan].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from helper import *\n",
    "\n",
    "def w2v_vec(text):\n",
    "    text = text.split()\n",
    "    embeddings = [w2v[word] for word in words if word in w2v]\n",
    "    sentence_emb = sum(embeddings)/w2v.vector_size\n",
    "    return sentence_emb\n",
    "\n",
    "def cos_sim(v1,v2):\n",
    "  score = cosine_similarity([v1], [v2])[0][0]\n",
    "  return score\n",
    "    \n",
    "path='../reports/corpus.xlsx'\n",
    "descriptions = get_column_values(path, 'descriptions_measures', 'A')\n",
    "targets = get_column_values(path, 'descriptions_measures', 'B')\n",
    "models = ['bow','tfidf','word2vec','sbert']\n",
    "preprocessing = False\n",
    "version_w2v = 'glove-twitter-200'\n",
    "version_sbert = 'bert-base-nli-mean-tokens'\n",
    "version_bow = 'preprocessedbow_model.joblib'\n",
    "version_tfidf = 'preprocessedtfidf_model.joblib'\n",
    "corpus = ['Descriptions']\n",
    "tm = TextModels(excel_path=path, columns=corpus,\n",
    "                 word2vec_version=version_w2v, sbert_model=version_sbert)\n",
    "n = 10\n",
    "Q8 = 'Create a report that shows the number of settlement applications approved during the month, their approved amount,\\\n",
    "      the written off balance, the average days to approval, their average and median duration and their entry principal and balance, \\\n",
    "        for September 2020 per DCA and application type. The report should be produced on Earth portfolio. '\n",
    "target_sample = 'Balance on arrangement creation'\n",
    "\n",
    "\n",
    "scores = get_similarity_scores(text=Q8, documents=targets, encoding_method='word2vec',\n",
    "                               version=version_w2v, tm=tm, preprocessing=preprocessing )\n",
    "\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_Q8 = tm.encode_word2vec(sentence=Q8, preprocessing=preprocessing)\n",
    "glove_target_sample = tm.encode_word2vec(sentence=target_sample, preprocessing=preprocessing)\n",
    "\n",
    "\n",
    "\n",
    "glove_Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.7266901e-03 -5.2159498e-03  8.9269993e-04  4.1858002e-04\n",
      "  6.2018000e-03  4.0180152e-03  6.3200500e-03 -5.1428499e-03\n",
      " -2.4992495e-04 -4.5147650e-03 -4.9845502e-03  4.4995494e-04\n",
      " -9.8515498e-03  9.8384998e-04 -4.2974604e-03  3.5630499e-03\n",
      "  1.4208248e-03  3.6028496e-04 -4.0710745e-03  2.6349584e-03\n",
      "  1.6883650e-03  1.6630000e-03 -4.5094001e-03 -2.0826503e-03\n",
      " -1.2412150e-03  1.4283050e-02  1.8301500e-03  6.9146003e-03\n",
      "  2.1180550e-03  2.3239499e-03 -1.1422550e-03  3.0653001e-04\n",
      " -2.5102999e-03 -2.4493001e-03  5.0821993e-03 -3.5678900e-03\n",
      "  3.3366247e-03  5.1048503e-04  5.8827000e-03 -5.4690003e-04\n",
      "  7.5462502e-03 -1.5127101e-03  9.9425006e-04  4.9095000e-03\n",
      "  5.3505506e-03 -1.9670010e-04 -7.2230948e-03 -2.4558499e-03\n",
      "  1.5668500e-03 -5.2830498e-03  2.2397500e-03 -3.0819996e-04\n",
      " -6.2564999e-04  2.2696999e-03 -7.0864498e-04 -1.3213800e-03\n",
      "  4.8332498e-03 -2.8948497e-03  1.1388500e-03  8.9293451e-04\n",
      " -8.9122995e-04 -3.9040498e-04  8.9254498e-04 -4.0206448e-03\n",
      " -2.9283601e-03  3.0894501e-03  5.0009252e-03  1.8628101e-03\n",
      " -3.8361319e-03  1.9977903e-03 -4.8129997e-04  3.6465002e-03\n",
      "  1.5839851e-03 -3.8399994e-05  9.2029991e-04 -2.3277500e-03\n",
      "  2.5793400e-03  1.3860699e-03 -1.6185502e-04  4.9019000e-03\n",
      "  4.6407199e-03  3.8989151e-03  1.6188151e-03 -1.7433001e-03\n",
      " -3.0134099e-03 -2.9273003e-03  1.9103498e-03 -2.9001797e-03\n",
      " -4.2578350e-03  1.0064599e-03  8.1045000e-04  5.3586499e-03\n",
      " -1.5881801e-03 -4.7481502e-03 -8.8649991e-05  7.9634995e-04\n",
      "  3.3523000e-03 -3.9129849e-03 -6.3414997e-03  3.2060500e-03\n",
      "  7.1785005e-04  2.1626010e-04  1.5940501e-03  5.6518000e-03\n",
      "  3.4852999e-03 -2.5130850e-03  2.6734425e-03 -1.6045001e-03\n",
      " -4.6682698e-03  3.1684500e-03  1.5221187e-03  1.3253150e-03\n",
      " -4.8127901e-03 -6.6637504e-04  1.4786002e-03 -1.3518601e-03\n",
      "  3.0061200e-03  4.7526448e-03  4.4077000e-04  6.9562499e-03\n",
      "  2.5780150e-03  2.6159501e-03  2.5548500e-03  9.4040995e-04\n",
      "  5.4704500e-03 -1.8628508e-04  1.6215999e-03  3.6068977e-04\n",
      "  4.3515502e-03  3.6749954e-03  3.9331652e-03  1.9748500e-03\n",
      " -5.3555495e-04  1.1839799e-03 -2.3044497e-03 -3.4822049e-03\n",
      " -2.8723449e-04  3.6328251e-03 -4.3360097e-03 -4.6579503e-03\n",
      " -1.1961450e-03  1.8294000e-03  2.2220497e-03  3.2290004e-03\n",
      "  1.2891999e-03 -1.0433649e-03 -3.0867099e-03 -2.0182850e-03\n",
      " -1.2593002e-03  4.0087500e-03  3.0622501e-03 -2.1794006e-04\n",
      " -4.9121499e-02  8.0149504e-04 -2.8537496e-04 -1.9615010e-04\n",
      "  9.8805001e-04 -2.4223002e-03 -7.2968500e-03  4.2064502e-03\n",
      " -4.0801503e-03  4.1421498e-03  2.1580007e-04 -2.4107606e-03\n",
      "  3.6484553e-03 -3.8720004e-04  5.8218004e-04  2.5145900e-03\n",
      "  2.3099501e-03 -3.4791499e-03  7.9694502e-03 -1.2265002e-04\n",
      " -1.6631499e-03 -2.5072300e-03  5.2690000e-04  4.9151001e-03\n",
      "  6.2351204e-03  1.2822502e-03  2.6355749e-03  7.3099953e-05\n",
      "  1.6644499e-03 -1.5314296e-03 -1.8658999e-03  2.8239499e-04\n",
      " -1.9365202e-03 -1.6862000e-03 -5.8847321e-03 -5.5501000e-03\n",
      "  2.0296751e-03 -3.3680252e-03  4.9403502e-04 -3.7738050e-03\n",
      "  9.8309992e-03 -8.6629984e-04  8.6901011e-04  5.9300796e-03\n",
      "  5.1997500e-03  3.7774500e-03 -8.7702501e-05 -3.8357002e-03]\n"
     ]
    }
   ],
   "source": [
    "def w2v_vec(text,w2v):\n",
    "    text = text.split()\n",
    "    embeddings = [w2v[word] for word in text if word in w2v]\n",
    "    sentence_emb = sum(embeddings)/w2v.vector_size\n",
    "    return sentence_emb\n",
    "\n",
    "def cos_sim(t1,t2,w2v):\n",
    "  v1 = w2v_vec(t1,w2v)\n",
    "  v2 = w2v_vec(t2,w2v)\n",
    "  score = cosine_similarity([v1], [v2])[0][0]\n",
    "  return score\n",
    "\n",
    "w2v = api.load(\"glove-twitter-200\")\n",
    "Q8 = 'Create a report that shows the number of settlement applications approved during the month, their approved amount,\\\n",
    "      the written off balance, the average days to approval, their average and median duration and their entry principal and balance, \\\n",
    "        for September 2020 per DCA and application type. The report should be produced on Earth portfolio. '\n",
    "target_sample = 'Balance on arrangement creation'\n",
    "\n",
    "\n",
    "sim = cos_sim(Q8,target_sample,w2v)\n",
    "\n",
    "query_encoding = w2v_vec(target_sample, w2v) \n",
    "doc_encoding = w2v_vec(Q8, w2v)\n",
    "similarity_score = cosine_similarity([query_encoding], [doc_encoding])[0][0]\n",
    "\n",
    "print('doc_encoding shape:', doc_encoding.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6730b402c0f33b6bed7f8d0f7f3f069d5734816b753f081e1b7690f9108853e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
